{
    "contents" : "//  GBM by Greg Ridgeway  Copyright (C) 2003\n//#define NOISY_DEBUG\n#include \"gbm_engine.h\"\n\nCGBM::CGBM()\n{\n    adFadj = NULL;\n    adZ = NULL;\n    afInBag = NULL;\n    aiNodeAssign = NULL;\n    aNodeSearch = NULL;\n\n    cDepth = 0;\n    cMinObsInNode = 0;\n    dBagFraction = 0.0;\n    dLambda = 0.0;\n    fInitialized = false;\n    cTotalInBag = 0;\n    cTrain = 0;\n    cValid = 0;\n\n    pData = NULL;\n    pDist = NULL;\n    pNodeFactory = NULL;\n    ptreeTemp = NULL;\n}\n\n\nCGBM::~CGBM()\n{\n    if(adFadj != NULL)\n    {\n        delete [] adFadj;\n        adFadj = NULL;\n    }\n    if(adZ != NULL)\n    {\n        delete [] adZ;\n        adZ = NULL;\n    }\n    if(afInBag != NULL)\n    {\n        delete [] afInBag;\n        afInBag = NULL;\n    }\n    if(aiNodeAssign != NULL)\n    {\n        delete [] aiNodeAssign;\n        aiNodeAssign = NULL;\n    }\n    if(aNodeSearch != NULL)\n    {\n        delete [] aNodeSearch;\n        aNodeSearch = NULL;\n    }\n    if(ptreeTemp != NULL)\n    {\n        delete ptreeTemp;\n        ptreeTemp = NULL;\n    }\n    // must delete the node factory last!!! at least after deleting trees\n    if(pNodeFactory != NULL)\n    {\n        delete pNodeFactory;\n        pNodeFactory = NULL;\n    }\n}\n\n\nGBMRESULT CGBM::Initialize\n(\n    CDataset *pData,\n    CDistribution *pDist,\n    double dLambda,\n    unsigned long cTrain,\n    double dBagFraction,\n    unsigned long cDepth,\n    unsigned long cMinObsInNode,\n    unsigned long cNumClasses,\n    int cGroups\n)\n{\n    GBMRESULT hr = GBM_OK;\n    unsigned long i=0;\n\n    if(pData == NULL)\n    {\n        hr = GBM_INVALIDARG;\n        goto Error;\n    }\n    if(pDist == NULL)\n    {\n        hr = GBM_INVALIDARG;\n        goto Error;\n    }\n\n    this->pData = pData;\n    this->pDist = pDist;\n    this->dLambda = dLambda;\n    this->cTrain = cTrain;\n    this->dBagFraction = dBagFraction;\n    this->cDepth = cDepth;\n    this->cMinObsInNode = cMinObsInNode;\n    this->cGroups = cGroups;\n\n    // allocate the tree structure\n    ptreeTemp = new CCARTTree;\n    if(ptreeTemp == NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n\n    cValid = pData->cRows - cTrain;\n    cTotalInBag = (unsigned long)(dBagFraction*cTrain);\n    adZ = new double[(pData->cRows) * cNumClasses];\n\n    if(adZ == NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n    adFadj = new double[(pData->cRows) * cNumClasses];\n    if(adFadj == NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n\n    for (i=0; i<(pData->cRows)*cNumClasses; i++)\n    {\n        adFadj[i] = 0.0;\n    }\n\n    pNodeFactory = new CNodeFactory();\n    if(pNodeFactory == NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n    hr = pNodeFactory->Initialize(cDepth);\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n    ptreeTemp->Initialize(pNodeFactory);\n\n    // array for flagging those observations in the bag\n    afInBag = new bool[cTrain];\n    if(afInBag==NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n    // aiNodeAssign tracks to which node each training obs belongs\n    aiNodeAssign = new ULONG[cTrain];\n    if(aiNodeAssign==NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n    // NodeSearch objects help decide which nodes to split\n    aNodeSearch = new CNodeSearch[2*cDepth+1];\n    if(aNodeSearch==NULL)\n    {\n        hr = GBM_OUTOFMEMORY;\n        goto Error;\n    }\n    for(i=0; i<2*cDepth+1; i++)\n    {\n        aNodeSearch[i].Initialize(cMinObsInNode);\n    }\n    vecpTermNodes.resize(2*cDepth+1,NULL);\n\n    fInitialized = true;\n\nCleanup:\n    return hr;\nError:\n    goto Cleanup;\n}\n\n\n\n\nGBMRESULT CGBM::Predict\n(\n    unsigned long iVar,\n    unsigned long cTrees,\n    double *adF,\n    double *adX,\n    unsigned long cLength\n)\n{\n    GBMRESULT hr = GBM_OK;\n\n\n    return hr;\n}\n\n\nGBMRESULT CGBM::Predict\n(\n    double *adX,\n    unsigned long cRow,\n    unsigned long cCol,\n    unsigned long cTrees,\n    double *adF\n)\n{\n    GBMRESULT hr = GBM_OK;\n\n\n    return hr;\n}\n\n\n\nGBMRESULT CGBM::GetVarRelativeInfluence\n(\n    double *adRelInf,\n    unsigned long cTrees\n)\n{\n    GBMRESULT hr = GBM_OK;\n    int iVar=0;\n\n    for(iVar=0; iVar<pData->cCols; iVar++)\n    {\n        adRelInf[iVar] = 0.0;\n    }\n\n    return hr;\n}\n\n\nGBMRESULT CGBM::PrintTree()\n{\n    GBMRESULT hr = GBM_OK;\n\n    hr = ptreeTemp->Print();\n    if(GBM_FAILED(hr)) goto Error;\n\nCleanup:\n    return hr;\nError:\n    goto Cleanup;\n}\n\n\nGBMRESULT CGBM::iterate\n(\n    double *adF,\n    double &dTrainError,\n    double &dValidError,\n    double &dOOBagImprove,\n    int &cNodes,\n    int cNumClasses,\n    int cClassIdx\n)\n{\n    GBMRESULT hr = GBM_OK;\n    unsigned long i = 0;\n    unsigned long cBagged = 0;\n    int cIdxOff = cClassIdx * (cTrain + cValid);\n\n //   for(i=0; i < cTrain + cIdxOff; i++){ adF[i] = 0;}\n    if(!fInitialized)\n    {\n        hr = GBM_FAIL;\n        goto Error;\n    }\n\n    dTrainError = 0.0;\n    dValidError = 0.0;\n    dOOBagImprove = 0.0;\n\n    vecpTermNodes.assign(2*cDepth+1,NULL);\n\n    // randomly assign observations to the Bag\n\n    if (cClassIdx == 0)\n    {\n        if (!IsPairwise())\n        {\n            // regular instance based training\n            for(i=0; i<cTrain; i++) /* && (cBagged < cTotalInBag); i++) */\n            {\n                if(unif_rand()*(cTrain-i) < cTotalInBag-cBagged)\n                {\n                    afInBag[i] = true;\n                    cBagged++;\n                }\n                else\n                {\n                    afInBag[i] = false;\n                }\n/*                if (cBagged >= cTotalInBag){\n                    break; \t\t\n                } */\n            }\n            // the remainder is not in the bag\n            for( ; i<cTrain; i++)\n            {\n                afInBag[i] = false;\n            }\n        }\n        else\n        {\n            // for pairwise training, sampling is per group\n            // therefore, we will not have exactly cTotalInBag instances\n\n            double dLastGroup = -1;\n            bool chosen = false;\n            unsigned int cBaggedGroups = 0;\n            unsigned int cSeenGroups   = 0;\n            unsigned int cTotalGroupsInBag = (unsigned long)(dBagFraction * cGroups);\n            if (cTotalGroupsInBag <= 0)\n            {\n                cTotalGroupsInBag = 1;\n            }\n            for(i=0; i<cTrain; i++)\n            {\n                const double dGroup = pData->adMisc[i];\n                if (dGroup != dLastGroup)\n                {\n                    if (cBaggedGroups >= cTotalGroupsInBag)\n                    {\n                        break;\n                    }\n\n                    // Group changed, make a new decision\n                    chosen = (unif_rand()*(cGroups - cSeenGroups) < cTotalGroupsInBag - cBaggedGroups);\n                    if (chosen)\n                    {\n                        cBaggedGroups++;\n                    }\n                    dLastGroup = dGroup;\n                    cSeenGroups++;\n                }\n                if (chosen)\n                {\n                    afInBag[i] = true;\n                    cBagged++;\n                }\n                else\n                {\n                    afInBag[i] = false;\n                }\n            }\n            // the remainder is not in the bag\n            for( ; i<cTrain; i++)\n            {\n                afInBag[i] = false;\n            }\n        }\n    }\n\n#ifdef NOISY_DEBUG\n    Rprintf(\"Compute working response\\n\");\n#endif\n\n    hr = pDist->ComputeWorkingResponse(pData->adY,\n                                       pData->adMisc,\n                                       pData->adOffset,\n                                       adF,\n                                       adZ,\n                                       pData->adWeight,\n                                       afInBag,\n                                       cTrain,\n                                       cIdxOff);\n\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n\n#ifdef NOISY_DEBUG\n    Rprintf(\"Reset tree\\n\");\n#endif\n    hr = ptreeTemp->Reset();\n#ifdef NOISY_DEBUG\n    Rprintf(\"grow tree\\n\");\n#endif\n\n    hr = ptreeTemp->grow(&(adZ[cIdxOff]), pData, &(pData->adWeight[cIdxOff]),\n                         &(adFadj[cIdxOff]), cTrain, cTotalInBag, dLambda, cDepth,\n                         cMinObsInNode, afInBag, aiNodeAssign, aNodeSearch,\n                         vecpTermNodes);\n\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n\n#ifdef NOISY_DEBUG\n    Rprintf(\"get node count\\n\");\n#endif\n    hr = ptreeTemp->GetNodeCount(cNodes);\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n\n    // Now I have adF, adZ, and vecpTermNodes (new node assignments)\n    // Fit the best constant within each terminal node\n#ifdef NOISY_DEBUG\n    Rprintf(\"fit best constant\\n\");\n#endif\n\n    hr = pDist->FitBestConstant(pData->adY,\n                                pData->adMisc,\n                                pData->adOffset,\n                                pData->adWeight,\n                                adF,\n                                adZ,\n                                aiNodeAssign,\n                                cTrain,\n                                vecpTermNodes,\n                                (2*cNodes+1)/3, // number of terminal nodes\n                                cMinObsInNode,\n                                afInBag,\n                                adFadj,\n                                cIdxOff);\n\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n\n    // update training predictions\n    // fill in missing nodes where N < cMinObsInNode\n    hr = ptreeTemp->Adjust(aiNodeAssign,&(adFadj[cIdxOff]),cTrain,\n                           vecpTermNodes,cMinObsInNode);\n    if(GBM_FAILED(hr))\n    {\n        goto Error;\n    }\n    ptreeTemp->SetShrinkage(dLambda);\n\n    if (cClassIdx == (cNumClasses - 1))\n    {\n        dOOBagImprove = pDist->BagImprovement(pData->adY,\n                                              pData->adMisc,\n                                              pData->adOffset,\n                                              pData->adWeight,\n                                              adF,\n                                              adFadj,\n                                              afInBag,\n                                              dLambda,\n                                              cTrain);\n    }\n\n    // update the training predictions\n    for(i=0; i < cTrain; i++)\n    {\n        int iIdx = i + cIdxOff;\n        adF[iIdx] += dLambda * adFadj[iIdx];\n    }\n\n    dTrainError = pDist->Deviance(pData->adY,\n                                  pData->adMisc,\n                                  pData->adOffset,\n                                  pData->adWeight,\n                                  adF,\n                                  cTrain,\n                                  cIdxOff);\n\n    // update the validation predictions\n    hr = ptreeTemp->PredictValid(pData,cValid,&(adFadj[cIdxOff]));\n\n    for(i=cTrain; i < cTrain+cValid; i++)\n    {\n        adF[i + cIdxOff] += adFadj[i + cIdxOff];\n    }\n\n    if(pData->fHasOffset)\n    {\n        dValidError =\n            pDist->Deviance(pData->adY,\n                            pData->adMisc,\n                            pData->adOffset,\n                            pData->adWeight,\n                            adF,\n                            cValid,\n                            cIdxOff + cTrain);\n    }\n    else\n    {\n        dValidError = pDist->Deviance(pData->adY,\n                                      pData->adMisc,\n                                      NULL,\n                                      pData->adWeight,\n                                      adF,\n                                      cValid,\n                                      cIdxOff + cTrain);\n    }\n\nCleanup:\n    return hr;\nError:\n    goto Cleanup;\n}\n\n\nGBMRESULT CGBM::TransferTreeToRList\n(\n    int *aiSplitVar,\n    double *adSplitPoint,\n    int *aiLeftNode,\n    int *aiRightNode,\n    int *aiMissingNode,\n    double *adErrorReduction,\n    double *adWeight,\n    double *adPred,\n    VEC_VEC_CATEGORIES &vecSplitCodes,\n    int cCatSplitsOld\n)\n{\n    GBMRESULT hr = GBM_OK;\n\n    hr = ptreeTemp->TransferTreeToRList(pData,\n                                        aiSplitVar,\n                                        adSplitPoint,\n                                        aiLeftNode,\n                                        aiRightNode,\n                                        aiMissingNode,\n                                        adErrorReduction,\n                                        adWeight,\n                                        adPred,\n                                        vecSplitCodes,\n                                        cCatSplitsOld,\n                                        dLambda);\n\n    return hr;\n}\n\n\n",
    "created" : 1444789518180.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2483050217",
    "id" : "2E79EF19",
    "lastKnownWriteTime" : 1426060578,
    "path" : "C:/Users/ambar_000/Desktop/COMP594/Blum Project/R Code/gbm/src/gbm_engine.cpp",
    "project_path" : "src/gbm_engine.cpp",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "cpp"
}